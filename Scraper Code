--IMPORTS--

from selenium import webdriver
from selenium.webdriver.common.by import By
from time import sleep
import pandas as pd


--INITIALISE--

my_url = "https://www.amazon.in/"
driver = webdriver.Chrome()
driver.get(my_url)
input_search = driver.find_element(By.ID,"twotabsearchtextbox")
srch_button = driver.find_element(By.XPATH,"(//input[@type='submit'])[1]")
input_search.send_keys("chocolates under 500")
sleep(1)
srch_button.click()

--SCRAP LOOP--

products = []
for i in range(4):
    print('Scraping page', i+1)
    product = driver.find_elements(By.XPATH,"//span[@class='a-size-base-plus a-color-base a-text-normal']")
    for p in product:
        products.append(p.text)
    next_button = driver.find_element(By.XPATH,"//a[@class='s-pagination-item s-pagination-next s-pagination-button s-pagination-separator'] ")
    next_button.click()
    sleep(2)

len(products)

--DATA CONVERSION--

df = pd.DataFrame(products)
df.to_csv("chocolates500.csv",index=False)
driver.quit()

